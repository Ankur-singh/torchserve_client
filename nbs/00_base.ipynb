{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Docker Command to start torchserve docker\n",
    "\n",
    "```bash\n",
    "docker run --rm -it -p 8080:8080 -p 8081:8081 -p 8082:8082 -p 7070:7070 -p 7071:7071 pytorch/torchserve:latest\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseClient:\n",
    "    def __init__(self, base_url=None):\n",
    "        base_url = base_url if base_url else os.environ.get('TORCHSERVE_URL', 'http://localhost')\n",
    "        self.base_url = base_url.rstrip('/')\n",
    "\n",
    "    def _make_request(self, method, endpoint, json=None, params=None, files=None):\n",
    "        \"\"\"\n",
    "        json: dict. The JSON body of the request.\n",
    "        params: dict. The URL parameters of the request.\n",
    "        files: [dict]. The files to upload.\n",
    "        \"\"\"\n",
    "        url = f\"{self.base_url}{endpoint}\"\n",
    "        response = requests.request(method, url, json=json, params=params, files=files)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}(base_url={self.base_url})\"\n",
    "    \n",
    "    def _filter_none_values(self, data):\n",
    "        return {key: value for key, value in data.items() if value is not None}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Management Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ManagementClient(BaseClient):\n",
    "    def __init__(self, base_url=None, port=8081):\n",
    "        super().__init__(base_url)\n",
    "        self.port = port\n",
    "        self.base_url = f\"{self.base_url}:{self.port}\"\n",
    "\n",
    "    def register_model(self, url, model_name=None, handler=None, runtime=None,\n",
    "                       batch_size=1, max_batch_delay=100, initial_workers=0,\n",
    "                       synchronous=False, response_timeout=120):\n",
    "        data = {\n",
    "            'url': url,\n",
    "            'model_name': model_name,\n",
    "            'handler': handler,\n",
    "            'runtime': runtime,\n",
    "            'batch_size': batch_size,\n",
    "            'max_batch_delay': max_batch_delay,\n",
    "            'initial_workers': initial_workers,\n",
    "            'synchronous': synchronous,\n",
    "            'response_timeout': response_timeout\n",
    "        }\n",
    "        data = self._filter_none_values(data)\n",
    "        return self._make_request('POST', '/models', json=data)\n",
    "\n",
    "    def scale_workers(self, model_name, version=None, min_worker=1, max_worker=None,\n",
    "                      synchronous=False, timeout=-1):\n",
    "        if version:\n",
    "            endpoint = f\"/models/{model_name}/{version}\"\n",
    "        else:\n",
    "            endpoint = f\"/models/{model_name}\"\n",
    "\n",
    "        params = {\n",
    "            'min_worker': min_worker,\n",
    "            'max_worker': max_worker if max_worker is not None else min_worker,\n",
    "            'synchronous': synchronous,\n",
    "            'timeout': timeout\n",
    "        }\n",
    "\n",
    "        return self._make_request('PUT', endpoint, json=params)\n",
    "    \n",
    "    def describe_model(self, model_name, version=None, customized=False):\n",
    "        \"\"\"\n",
    "        Returns the model description.\n",
    "        version :  is optional. if `all` return status of all version of a model. If not provided, the latest version will be returned.\n",
    "        allowed\n",
    "        \"\"\"\n",
    "        params = {}\n",
    "        if customized:\n",
    "            params['customized'] = customized\n",
    "            \n",
    "        if version:\n",
    "            endpoint = f\"/models/{model_name}/{version}\"\n",
    "        else:\n",
    "            endpoint = f\"/models/{model_name}\"\n",
    "        return self._make_request('GET', endpoint, params=params)\n",
    "    \n",
    "    def unregister_model(self, model_name, version=None):\n",
    "        if version:\n",
    "            endpoint = f\"/models/{model_name}/{version}\"\n",
    "        else:\n",
    "            endpoint = f\"/models/{model_name}\"\n",
    "\n",
    "        return self._make_request('DELETE', endpoint)\n",
    "    \n",
    "    def list_models(self, limit=100, next_page_token=None):\n",
    "        params = {\n",
    "            'limit': limit,\n",
    "            'next_page_token': next_page_token\n",
    "        }\n",
    "        params = self._filter_none_values(params)\n",
    "        return self._make_request('GET', '/models', params=params)\n",
    "    \n",
    "    def api_description(self):\n",
    "        return self._make_request('OPTIONS', '/')\n",
    "    \n",
    "    def set_default_version(self, model_name, version):\n",
    "        endpoint = f\"/models/{model_name}/{version}/set-default\"\n",
    "        return self._make_request('PUT', endpoint)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class InferenceClient(BaseClient):\n",
    "    def __init__(self, base_url=None, port=8080):\n",
    "        super().__init__(base_url)\n",
    "        self.port = port\n",
    "        self.base_url = f\"{self.base_url}:{self.port}\"\n",
    "\n",
    "    def api_description(self):\n",
    "        return self._make_request('OPTIONS', '/')\n",
    "    \n",
    "    def health_check(self):\n",
    "        return self._make_request('GET', '/ping')\n",
    "    \n",
    "    def prediction(self, model_name, data, version=None):\n",
    "        \"\"\"\n",
    "        inference_data = [\n",
    "            ('data', open('docs/images/dogs-before.jpg', 'rb')),\n",
    "            ('data', open('docs/images/kitten_small.jpg', 'rb')),\n",
    "        ]\n",
    "        \"\"\"\n",
    "        if version:\n",
    "            endpoint = f\"/predictions/{model_name}/{version}\"\n",
    "        else:\n",
    "            endpoint = f\"/predictions/{model_name}\"\n",
    "\n",
    "        return self._make_request('POST', endpoint, files=data)\n",
    "    \n",
    "    def explaination(self, model_name, data):\n",
    "        \"\"\"\n",
    "        data <string : bytes>\n",
    "        \"\"\"\n",
    "        endpoint = f\"/explanations/{model_name}\"\n",
    "        return self._make_request('POST', endpoint, files=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
